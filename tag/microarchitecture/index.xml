<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>microarchitecture | David Schall</title><link>https://dhschall.github.io/tag/microarchitecture/</link><atom:link href="https://dhschall.github.io/tag/microarchitecture/index.xml" rel="self" type="application/rss+xml"/><description>microarchitecture</description><generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Wed, 22 Jun 2022 13:50:00 +0000</lastBuildDate><image><url>https://dhschall.github.io/media/icon_hu981027b910824d70bbcbf5f2f23e00a3_21003_512x512_fill_lanczos_center_3.png</url><title>microarchitecture</title><link>https://dhschall.github.io/tag/microarchitecture/</link></image><item><title>Lukewarm serverless functions: characterization and optimization</title><link>https://dhschall.github.io/talk/lukewarm-serverless-functions-characterization-and-optimization/</link><pubDate>Wed, 22 Jun 2022 13:50:00 +0000</pubDate><guid>https://dhschall.github.io/talk/lukewarm-serverless-functions-characterization-and-optimization/</guid><description>&lt;p>Serverless computing has emerged as a widely-used paradigm for running services in the cloud. In serverless, developers organize their applications as a set of functions, which are invoked on-demand in response to events, such as an HTTP request. To avoid long start-up delays of launching a new function instance, cloud providers tend to keep recently-triggered instances idle (or warm) for some time after the most recent invocation in anticipation of future invocations. Thus, at any given moment on a server, there may be thousands of warm instances of various functions whose executions are interleaved in time based on incoming invocations.&lt;/p>
&lt;p>This paper observes that (1) there is a high degree of interleaving among warm instances on a given server; (2) the individual warm functions are invoked relatively infrequently, often at the granularity of seconds or minutes; and (3) many function invocations complete within a few milliseconds. Interleaved execution of rarely invoked functions on a server leads to thrashing of each function&amp;rsquo;s microarchitectural state between invocations. Meanwhile, the short execution time of a function impedes amortization of the warm-up latency of the cache hierarchy, causing a 31-114% increase in CPI compared to execution with warm microarchitectural state. We identify on-chip misses for instructions as a major contributor to the performance loss. In response we propose Jukebox, a record-and-replay instruction prefetcher specifically designed for reducing the start-up latency of warm function instances. Jukebox requires just 32KB of metadata per function instance and boosts performance by an average of 18.7% for a wide range of functions, which translates into a corresponding throughput improvement.&lt;/p></description></item><item><title>vSwam-u: Microarchitectural Research for Severless</title><link>https://dhschall.github.io/talk/vswam-u-microarchitectural-research-for-severless/</link><pubDate>Sat, 18 Jun 2022 17:15:00 +0000</pubDate><guid>https://dhschall.github.io/talk/vswam-u-microarchitectural-research-for-severless/</guid><description>&lt;p>Serverless computing has emerged as a widely used paradigm for deploying services in the cloud. In serverless, developers organize their application as a set of functions, which are invoked on-demand in response to a trigger, such as user request or an invocation by another function.&lt;/p>
&lt;p>Recent studies of production data reveal drastic differences in the characteristics of serverless workloads compared to conventional cloud workloads: short execution time and infrequent invocation of function instances. Performance studies further finds that serverless workloads are inefficient when running on modern CPUs designed for traditional long-running workloads. To make serverless workload execution efficient, there is a strong need to understand more about the detailed implications serverless workload characteristics have on modern hardware.&lt;/p>
&lt;p>However, existing platforms that support the required level of detail make significant simplifications in the test setup and the software stack to achieve feasible simulation times. Prior work often lacks the key layers of the serverless software stack, such as containerization and HTTP-level communication fabric, to simplify and increase the simulation speed. However, the short execution time of serverless functions leads to a significant fraction of execution time spent in system layers. Such simplifications may result in wrong experimental data and, consequently, mislead the systems researchers.&lt;/p>
&lt;p>With vSwarm-μ we are addressing the challenges of serverless host server simulation and allow researchers to conduct experiments with systems representative of a modern serverless cloud. To achieve this, the vSwarm-u framework integrates various serverless workloads packages as containerized functions and featuring the full communication stack with gem5, the state-of-the-art research platform for system- and microarchitecture. This allows researcher to perform cycles accurate simulation of the representative serverless software stack in gem5’s full system mode.&lt;/p>
&lt;p>Furthermore, vSwarm-u includes the infrastructure to drive function instances running on the simulated serverless host server without interfering or simplifying the complexity of the test system. The robust evaluation methodology allows benchmarking and microarchitecture analysis in a realistic scenario.&lt;/p></description></item></channel></rss>